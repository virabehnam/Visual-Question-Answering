# -*- coding: utf-8 -*-
"""VisualQuestionAnswering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_STto_eEj9dxcHay3uDP2s6VYu4Sc7fa
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import random, os, csv
import pandas as pd
import cv2 as cv
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
import numpy as np

def download_if_missing(url, target, extract=True):
  if os.path.exists(target):
    return target
  return tf.keras.utils.get_file(target, origin=url, extract=extract)

colab_root = "/content/"

csv_path = os.path.join(colab_root, "starter.csv")
download_if_missing("https://storage.googleapis.com/applied-dl/mini-vqa/starter.csv",
                     csv_path)

YOUR_THUMBNAILS_URL = 'https://storage.cloud.google.com/vira-behnam/thumbnails.zip'
thumbnails_file = os.path.join(colab_root, "thumbnails.zip")
images_folder = os.path.join(colab_root, 'thumbnails/')
download_if_missing(YOUR_THUMBNAILS_URL,
                    thumbnails_file,
                    extract=False)

from google.colab import drive 
drive.mount('/content/drive')

# !unzip -q $thumbnails_file -d $images_folder
import zipfile
with zipfile.ZipFile('/content/drive/My Drive/thumbnails.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/thumbnails/')

!ls $images_folder

df = pd.read_csv("starter.csv", header=None)

# for question, answer, image_name in data:
#   img_path = os.path.join(images_folder, image_name)
#   assert os.path.exists(img_path)

with open('starter.csv') as myfile:
   reader = csv.reader(myfile, delimiter=',')
   for row in reader:
      question, answer, image = row
      image = image.strip()
      assert os.path.exists(os.path.join("thumbnails/", image))

path = r"thumbnails/"
random_filename = random.choice([
    x for x in os.listdir(path)
    if os.path.isfile(os.path.join(path, x))
])
print(random_filename)

img = cv.imread("thumbnails/" + random_filename)
plt.imshow(img)

for index, row in df.iterrows():
  # print(row[2])
  if (row[2] == str(random_filename)):
    print("Q: " + row[0] + " A: " + row[1])
    break

df

# Convert the answers column in the starter CSV to 1.0 and 0.0

df[1].replace('yes', np.float32(1.0), inplace=True)
df[1].replace('no', np.float32(0.0), inplace=True)

df[1] = tf.dtypes.cast(df[1], tf.float32)  # [1, 2], dtype=tf.int32

# Convert the image filenames in the starter CSV to absolute paths

df[2] = '/content/thumbnails/' + df[2]

df

# Shuffle the starter CSV
# Remove 4,000 rows (or so) and move them to a separate file or data structure
df = df.sample(frac=1).reset_index(drop=True)

test_df = pd.DataFrame(df)[-4000:].copy(deep=True).reset_index(drop=True)

train_df = df[:-4000]

df[1].dtype

# Limit the size of the starter CSV to 20,000 rows
# Balance the data (so you have an equal number of "yes" and "no" answers) 
# in your 20,000 rows

# from https://stackoverflow.com/questions/45839316/pandas-balancing-data
def sampling_k_elements(group, k=10000):
    if len(group) < k:
        return group
    return group.sample(k)

mini_train_df = df.groupby(row[1]).apply(sampling_k_elements).reset_index(drop=True)

X_train, X_valid = train_test_split(mini_train_df, test_size=0.2)

X_train[1].dtype

X_train.size

X_valid.size

#display images from each set

filename = os.path.join(path, X_train[2][6]) #randomly selected images
filename_val = os.path.join(path, X_valid[2][97])

print("1. Example of training set image: ", filename)
img = cv.imread(str(filename))
plt.imshow(img)
plt.figure()
print("2. Example of validation set image: ", filename_val)
img2 = cv.imread(str(filename_val))
plt.imshow(img2);

import numpy as np
import matplotlib.pyplot as plt

bins = 10
data_train = X_train[1]
data_val = X_valid[1]

#confirming only yes/ no (1.0/ 0.0) answers and that the classes are balanced
# for training and validation sets.
plt.hist(data_train, bins, histtype='bar', stacked=False, fill=True)
plt.show()
plt.hist(data_val, bins, histtype='bar', stacked=False, fill=True)
plt.show()

# Create a feature extraction model.
image_model = tf.keras.applications.InceptionV3(include_top=False,
                                                weights='imagenet')
new_input = image_model.input
hidden_layer = image_model.layers[-1].output
image_features_extract_model = tf.keras.Model(new_input, hidden_layer)

# A method to load an image off disk, and extract activations using 
# the model above. You should not need to modify this.
def image_to_activations(image_path):
  img = tf.io.read_file(image_path)
  img = tf.image.decode_jpeg(img, channels=3)
  img = tf.image.resize(img, (299, 299))
  activations = tf.keras.applications.inception_v3.preprocess_input(img)
  return activations, image_path

# Extract activations for every image in your train, validation,
# and test set -> set of the absolute paths to all of these images 
# (image_path_set). Populate with the absolute paths to all these images.
trainset = set(X_train[2])
testset = set(test_df[2])
validset = set(X_valid[2])

image_path_set = trainset.union(testset,validset)

print("Images to preprocess", len(image_path_set))
print("This make take a few minutes")

trainset

# This cell will extract activations for each image and save them to disk 
# in NumPy format.

# Create a dataset to load each image off disk, and extract activations
activation_dataset = tf.data.Dataset.from_tensor_slices(list(image_path_set))
activation_dataset = activation_dataset.map(
  image_to_activations, 
  num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(32)

# Save all activations to disk in NumPy format
for img_batch, path_batch in activation_dataset:
  batch_features = image_features_extract_model(img_batch)
  for bf, p in zip(batch_features, path_batch):
    path_of_feature = p.numpy().decode("utf-8")
    np.save(path_of_feature, bf.numpy())

# Populate these for your training set.
questions_train = X_train[0] # a list of absolute paths to images in your training set
answers_train = X_train[1] # a list of questions in your training set
images_train = X_train[2] # a list of answers (in numeric format) in your training set

# The order of these lists should match (e.g. the question, answer, and image 
# from row i of your train split of the starter CSV should be 
# questions_train[i], answers_train[i], images_train[i]).

print(X_train[1].dtype)

# Populate these for your validation set.
questions_val = X_valid[0]
answers_val = X_valid[1]
images_val =  X_valid[2]

print(X_valid[0].dtype, X_valid[1].dtype, X_valid[2].dtype)
print(X_train[0].dtype, X_train[1].dtype, X_train[2].dtype)

# Populate these for your test set
questions_test = test_df[0]
answers_test = test_df[1]
images_test = test_df[2]

VOCAB_SIZE = 3000

tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)
tokenizer.fit_on_texts(questions_train)

# Note, the tokenizer's word_index will not respect VOCAB_SIZE.
# but, that parameter will be respected in later methods,
# (for example, when you call text_to_sequences).
# Also note that '0' is a reserved index for padding.
print("Word index", len(tokenizer.word_index))

# Use the texts_to_sequences utility to vectorize your training, 
# validation, and test questions. 

sequences_train = tokenizer.texts_to_sequences(questions_train)
sequences_val = tokenizer.texts_to_sequences(questions_val)
sequences_test = tokenizer.texts_to_sequences(questions_test)

# To choose a reasonable sequence length, examine the length of all the 
# tokenized questions in the training set (in words).


count10 = 0
count15 = 0
count17 = 0

for i, row in enumerate(sequences_train, start = 0):
  if len(sequences_train[i]) > 10:
    count10 = count10 + 1
    if len(sequences_train[i]) > 15:
      count15 = count15 + 1
      if len(sequences_train[i]) > 16:
        count17 = count17 + 1

print("Over 10: " + str(count10))
print("Over 15: " + str(count15))
print("Over 17: " + str(count17))

# therefore, we limit the length to 17, which has 8.

len(sequences_train)

MAX_SEQ_LEN = 17

# Use the pad_sequences utility to pad your training, 
# validation, and test questions.

padded_train = tf.keras.preprocessing.sequence.pad_sequences(sequences_train, maxlen=MAX_SEQ_LEN)
padded_val = tf.keras.preprocessing.sequence.pad_sequences(sequences_val, maxlen=MAX_SEQ_LEN)
padded_test = tf.keras.preprocessing.sequence.pad_sequences(sequences_test, maxlen=MAX_SEQ_LEN)

padded_train
word_index = tokenizer.word_index
word_index

BATCH_SIZE = 32
BUFFER_SIZE = 1000

# Load cached activations off disk.
def load_np(img_path, question, answer):
  activations = np.load(img_path.decode('utf-8')+'.npy')
  return activations, question, answer, img_path

# This method will create a dataset that returns four elements.
# - a batch of activations (loaded from disk)
# - a batch of padded questions
# - a batch of numeric answers
# - a batch of absolute paths to the corresponding images
def create_dataset(images, sequences, answers):
  dataset = tf.data.Dataset.from_tensor_slices((images, 
                                                sequences, 
                                                answers))
  # Load the cached activations off disk
  def my_lambda(x, y, z):
    return tf.numpy_function(
      load_np, [x, y, z], [tf.float32, tf.int32, tf.float32, tf.string]
    )
  dataset = dataset.map(my_lambda, num_parallel_calls=tf.data.experimental.AUTOTUNE)
  
  # Shuffle and batch
  dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
  return dataset

# Call the above method to create train, val, and test datasets.

train_ds = create_dataset(images_train, padded_train, answers_train)
val_ds = create_dataset(images_val, padded_val, answers_val)
test_ds = create_dataset(images_test, padded_test, answers_test)

print(images_train.dtype, padded_train.dtype, answers_train.dtype)

my_iterator = iter(train_ds)
activations_batch, questions_batch, answers_batch, paths_batch = next(my_iterator)

# print(activations_batch.shape, 
#       questions_batch.shape, 
#       answers_batch.shape, 
#       paths_batch.shape)

print(activations_batch.dtype, 
      questions_batch.dtype, 
      answers_batch.dtype, 
      paths_batch.dtype)

answers_train.dtype

from tensorflow.keras.layers import Dense, Embedding, Flatten, Input, LSTM
from tensorflow.keras.models import Model, Sequential

# See https://keras.io/getting-started/functional-api-guide/ for the idea.

# Input to your vision model (activations from Inception-V3,
# loaded off disk disk by the dataset above).
image_input = Input(shape=(8, 8, 2048)) 
vision_model = Sequential()
# Used to reduce the number of parameters (rather using a dense layer here).
vision_model.add(tf.keras.layers.GlobalAveragePooling2D())
# Output of your vision model
encoded_image = vision_model(image_input) 

# padded_train
question_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32') # your code
embedded_question = Embedding(input_dim=3000, output_dim=256, input_length=MAX_SEQ_LEN)(question_input)
encoded_question = LSTM(256)(embedded_question)

# Concatenate the encoded image and question
merged = tf.keras.layers.concatenate([encoded_image, encoded_question])

# add a small dense layer -- tried this, but model did not perform well.
# dense = Dense(10, activation='softmax')(merged)

# Next, add a binary classifier on top
output = Dense(1, activation='sigmoid')(merged)

# Your final model
model = Model(inputs=[image_input, question_input], outputs=output)

model.summary()

model.compile(optimizer='adam', 
              loss='binary_crossentropy',
              metrics=['accuracy'])

from tensorflow.keras.utils import plot_model
plot_model(model, to_file='model.png')

# Retrieve a batch of data from your train dataset
activations_batch, questions_batch, answers_batch, paths_batch = next(iter(train_ds))

# Train them model repeatedly using model.train_on_batch

metrics = model.train_on_batch([activations_batch, questions_batch], answers_batch)
# metrics is a list (loss is metrics[0], accuracy is metrics[1])

metrics[0] #loss keeps going down as you run previous block more times.

for prediction, answer in zip(model.predict(x=[activations_batch, questions_batch]), answers_batch):
  print(prediction, answer.numpy())

# Mount drive
drive.mount('/gdrive')
drive_root = '/gdrive/My Drive/'

#  save checkpoints in drive
checkpoint_dir = os.path.join(drive_root, "checkpoints")
checkpoint_dir = os.path.join(checkpoint_dir, "hw4")

# Used for formatting
checkpoint_path = os.path.join(checkpoint_dir, "cp-{epoch:08d}.ckpt")

# Uncomment this if you'd like to create a checkpoints folder in your drive
print("Checkpoints directory is", checkpoint_dir)
if os.path.exists(checkpoint_dir):
  print("Checkpoints folder already exists")
else:
  print("Creating a checkpoints directory")
  os.makedirs(checkpoint_dir)

latest = tf.train.latest_checkpoint(checkpoint_dir)
if latest != None:
  print("Loading weights from", latest)
  model.load_weights(latest)
else:
  print("Checkpoint not found. Starting from scratch")

# Utilities to help record metrics.
train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')

val_loss = tf.keras.metrics.BinaryCrossentropy(name='val_loss')
val_accuracy = tf.keras.metrics.BinaryAccuracy(name='val_accuracy')

def evaluate(max_steps=None):
  steps = 0
  for activation_batch, question_batch, answer_batch, path_batch in val_ds:
    if max_steps != None and steps == max_steps:
      break
    predictions = model.predict(x=[activation_batch, question_batch])
    steps += 1 
    # Record metrics after each batch
    val_loss(answer_batch, predictions)
    val_accuracy(answer_batch, predictions)

# Complete this cell (there are only a few parts to write)
import time

# Used to track loss and accuracy as we go
# You should not need to modify these
train_loss_history, train_acc_history = [], []
val_loss_history, val_acc_history = [], []

epochs = 50 

# Training loop
for epoch in range(epochs):

  start = time.time()

  # Train for one epoch
  for activation_batch, question_batch, answer_batch, path_batch in train_ds:
    result = model.train_on_batch(x=[activation_batch, question_batch], y=answer_batch)

    # Record metrics after each batch
    train_loss(result[0])
    train_accuracy(result[1])

  # Evaluate for a few steps
  evaluate(max_steps=100)

  # Print progress
  # You should not need to modify this.
  template = 'Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, Val Loss {:.2f}, Val Accuracy {:.2f}, Time: {:.1f} secs'
  print(template.format(epoch,
                        train_loss.result(),
                        train_accuracy.result() * 100,
                        val_loss.result(),
                        val_accuracy.result() * 100,
                        time.time() - start))
  
  # Record history
  train_loss_history.append(train_loss.result())
  train_acc_history.append(train_accuracy.result() * 100)
  val_loss_history.append(val_loss.result())
  val_acc_history.append(val_accuracy.result() * 100)

  # Reset the metrics for the next epoch
  train_loss.reset_states()
  train_accuracy.reset_states()
  val_loss.reset_states()
  val_accuracy.reset_states()

  # Save a checkpoint after each epoch
  print("Saving weights")
  model.save_weights('checkpoint_dir.h5')

epochs = range(len(train_acc_history))

plt.title('Training and validation accuracy')
plt.plot(epochs, train_acc_history, color='blue', label='Train')
plt.plot(epochs, val_acc_history, color='orange', label='Val')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

_ = plt.figure()
plt.title('Training and validation loss')
plt.plot(epochs, train_loss_history, color='blue', label='Train')
plt.plot(epochs, val_acc_history, color='orange', label='Val')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

from tensorflow.keras.layers import Conv2D, MaxPooling2D

image_input = Input(shape=(8, 8, 2048)) 
vision_model = Sequential()
# Used to reduce the number of parameters (rather using a dense layer here).


vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
vision_model.add(Conv2D(256, (3, 3), activation='relu'))
# vision_model.add(MaxPooling2D((2, 2)))
vision_model.add(tf.keras.layers.GlobalAveragePooling2D())

# Output of your vision model
encoded_image = vision_model(image_input) 

# padded_train
question_input = Input(shape=(MAX_SEQ_LEN,), dtype='int32') # your code
embedded_question = Embedding(input_dim=3000, output_dim=256, input_length=MAX_SEQ_LEN)(question_input)
encoded_question = LSTM(256)(embedded_question)

# Concatenate the encoded image and question
merged = tf.keras.layers.concatenate([encoded_image, encoded_question])

# add a small dense layer -- tried this, but model did not perform well.
# dense = Dense(10, activation='softmax')(merged)

# Next, add a binary classifier on top
output = Dense(1, activation='sigmoid')(merged)

# Your final model
model2 = Model(inputs=[image_input, question_input], outputs=output)

model2.compile(optimizer='adam', 
              loss='binary_crossentropy',
              metrics=['accuracy'])

def evaluate(max_steps=None):
  steps = 0
  for activation_batch, question_batch, answer_batch, path_batch in val_ds:
    if max_steps != None and steps == max_steps:
      break
    predictions = model2.predict(x=[activation_batch, question_batch])
    steps += 1 
    # Record metrics after each batch
    val_loss(answer_batch, predictions)
    val_accuracy(answer_batch, predictions)

# Complete this cell (there are only a few parts to write)
import time

# Used to track loss and accuracy as we go
train_loss_history, train_acc_history = [], []
val_loss_history, val_acc_history = [], []

epochs = 50 

# Training loop
for epoch in range(epochs):

  start = time.time()

  # Train for one epoch
  for activation_batch, question_batch, answer_batch, path_batch in train_ds:
    result = model2.train_on_batch(x=[activation_batch, question_batch], y=answer_batch)

    # Record metrics after each batch
    train_loss(result[0])
    train_accuracy(result[1])

  # Evaluate for a few steps
  evaluate(max_steps=100)

  # Print progress
  template = 'Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, Val Loss {:.2f}, Val Accuracy {:.2f}, Time: {:.1f} secs'
  print(template.format(epoch,
                        train_loss.result(),
                        train_accuracy.result() * 100,
                        val_loss.result(),
                        val_accuracy.result() * 100,
                        time.time() - start))
  
  # Record history
  train_loss_history.append(train_loss.result())
  train_acc_history.append(train_accuracy.result() * 100)
  val_loss_history.append(val_loss.result())
  val_acc_history.append(val_accuracy.result() * 100)

  # Reset the metrics for the next epoch
  train_loss.reset_states()
  train_accuracy.reset_states()
  val_loss.reset_states()
  val_accuracy.reset_states()

  # Save a checkpoint after each epoch
  print("Saving weights")
  model2.save_weights('checkpoint_dir_model2.h5')

epochs = range(len(train_acc_history))

plt.title('Training and validation accuracy')
plt.plot(epochs, train_acc_history, color='blue', label='Train')
plt.plot(epochs, val_acc_history, color='orange', label='Val')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

_ = plt.figure()
plt.title('Training and validation loss')
plt.plot(epochs, train_loss_history, color='blue', label='Train')
plt.plot(epochs, val_acc_history, color='orange', label='Val')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# As an experiment, 2 convolutional layers were added to the image model before
# being concatenated with the embedded questions for the training set. The
# Conv2D's should be able to better train the model with more parameters, 
# however, the model did about as well as the previous one. Everything else 
# was kept the same. Based on the the results above, it seems that the second 
# model performed better on the validation set. Therefore, we will continue 
# training with it, and use it for testing in the following block.

# Calculate accuracy on the test set

test_loss = tf.keras.metrics.BinaryCrossentropy(name='test_loss')
test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')

def evaluate_test(max_steps=None):
  steps = 0
  for activation_batch, question_batch, answer_batch, path_batch in test_ds:
    if max_steps != None and steps == max_steps:
      break
    predictions = model2.predict(x=[activation_batch, question_batch])
    steps += 1 
    # Record metrics after each batch
    test_loss(answer_batch, predictions)
    test_accuracy(answer_batch, predictions)

evaluate_test(max_steps=100)

print('test loss, test acc:', test_loss.result(), test_accuracy.result())

